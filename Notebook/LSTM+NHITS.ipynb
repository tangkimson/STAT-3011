{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a508c-1557-41c9-8765-b63493e2695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import LSTM, NHITS\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6445315-e545-420f-8a56-4c6f7d0219e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cleaned_data/average_monthly_rating_messenger.csv')\n",
    "df['Month-Year'] = pd.to_datetime(df['Month-Year'], format='%Y-%m')\n",
    "df.rename(columns={'Month-Year': 'ds', 'averageRating': 'y'}, inplace=True)\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df['unique_id'] = 0\n",
    "\n",
    "Y_df = df \n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235f218-6c63-4d0b-86f9-ae2f283a5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS, LSTM\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calculate the split point (80% for training)\n",
    "split_point = int(len(Y_df) * 0.8)\n",
    "Y_train = Y_df.iloc[:split_point].copy()\n",
    "Y_test = Y_df.iloc[split_point:].copy()\n",
    "\n",
    "# Set horizon to match test set size\n",
    "horizon = len(Y_test)\n",
    "print(f\"\\nHorizon length: {horizon}\")\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    LSTM(\n",
    "        h=horizon,\n",
    "        max_steps=500,\n",
    "        scaler_type='standard',\n",
    "        encoder_hidden_size=64,\n",
    "        decoder_hidden_size=64,\n",
    "    ),\n",
    "    NHITS(\n",
    "        h=horizon,\n",
    "        input_size=2 * horizon,\n",
    "        max_steps=100,\n",
    "        n_freq_downsample=[2, 1, 1]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1b87c-6695-493d-be5d-e9d97377ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models on training data\n",
    "nf = NeuralForecast(models=models, freq='M')\n",
    "nf.fit(df=Y_train)\n",
    "\n",
    "# Generate predictions for test period\n",
    "Y_hat_df = nf.predict(Y_train).reset_index(drop=True)\n",
    "\n",
    "# Calculate metrics and weights for ensemble\n",
    "eval_results = {}\n",
    "model_weights = {}\n",
    "\n",
    "for model in ['LSTM', 'NHITS']:\n",
    "    eval_df = pd.DataFrame({\n",
    "        'ds': Y_test['ds'],\n",
    "        'actual': Y_test['y'],\n",
    "        'predicted': Y_hat_df[model].values[:len(Y_test)]\n",
    "    })\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(eval_df['actual'], eval_df['predicted']))\n",
    "    mae = mean_absolute_error(eval_df['actual'], eval_df['predicted'])\n",
    "    mape = np.mean(np.abs((eval_df['actual'] - eval_df['predicted']) / eval_df['actual'])) * 100\n",
    "    \n",
    "    eval_results[model] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    # Calculate weight as inverse of RMSE\n",
    "    model_weights[model] = 1/rmse\n",
    "\n",
    "# Normalize weights to sum to 1\n",
    "weight_sum = sum(model_weights.values())\n",
    "for model in model_weights:\n",
    "    model_weights[model] /= weight_sum\n",
    "\n",
    "print(\"\\nModel Weights:\")\n",
    "for model, weight in model_weights.items():\n",
    "    print(f\"{model}: {weight:.3f}\")\n",
    "\n",
    "# Create and train ensemble model for future predictions\n",
    "nf_future = NeuralForecast(models=models, freq='M')\n",
    "nf_future.fit(df=Y_df)\n",
    "Y_hat_future = nf_future.predict().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbf9c8-9802-478d-a3ac-1c74d46f6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ensemble predictions\n",
    "Y_hat_future['ENSEMBLE'] = 0\n",
    "for model in ['LSTM', 'NHITS']:\n",
    "    Y_hat_future['ENSEMBLE'] += Y_hat_future[model] * model_weights[model]\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 14))\n",
    "\n",
    "# Plot 1: Training and Test Performance\n",
    "Y_df.set_index('ds')['y'].plot(ax=ax1, linewidth=2, label='Actual', color='blue')\n",
    "\n",
    "# Add ensemble predictions to test set\n",
    "Y_hat_df['ENSEMBLE'] = 0\n",
    "for model in ['LSTM', 'NHITS']:\n",
    "    Y_hat_df['ENSEMBLE'] += Y_hat_df[model] * model_weights[model]\n",
    "\n",
    "# Plot individual model and ensemble predictions\n",
    "for model in ['LSTM', 'NHITS', 'ENSEMBLE']:\n",
    "    Y_hat_df.set_index('ds')[model].plot(ax=ax1, linewidth=2, label=f'{model} Predictions')\n",
    "\n",
    "train_split_date = Y_train.iloc[-1]['ds']\n",
    "ax1.axvline(x=train_split_date, color='r', linestyle='--', label='Train-Test Split')\n",
    "ax1.axvspan(Y_test['ds'].min(), Y_test['ds'].max(), alpha=0.1, color='gray', label='Test Period')\n",
    "\n",
    "ax1.set_title('Model Performance Comparison (Including Ensemble)', fontsize=22)\n",
    "ax1.set_ylabel('Monthly Rating', fontsize=20)\n",
    "ax1.set_xlabel('Timestamp [t]', fontsize=20)\n",
    "ax1.legend(prop={'size': 15})\n",
    "ax1.grid()\n",
    "\n",
    "# Plot 2: Future Predictions\n",
    "Y_df.set_index('ds')['y'].plot(ax=ax2, linewidth=2, label='Actual', color='blue')\n",
    "\n",
    "# Plot future predictions for all models including ensemble\n",
    "for model in ['LSTM', 'NHITS', 'ENSEMBLE']:\n",
    "    Y_hat_future.set_index('ds')[model].plot(ax=ax2, linewidth=2, label=f'{model} Predictions')\n",
    "\n",
    "ax2.set_title('Future Predictions (Including Ensemble)', fontsize=22)\n",
    "ax2.set_ylabel('Monthly Rating', fontsize=20)\n",
    "ax2.set_xlabel('Timestamp [t]', fontsize=20)\n",
    "ax2.legend(prop={'size': 15})\n",
    "ax2.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Calculate ensemble metrics for test period\n",
    "ensemble_predictions = Y_hat_df['ENSEMBLE'].values[:len(Y_test)]\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(Y_test['y'], ensemble_predictions))\n",
    "ensemble_mae = mean_absolute_error(Y_test['y'], ensemble_predictions)\n",
    "ensemble_mape = np.mean(np.abs((Y_test['y'] - ensemble_predictions) / Y_test['y'])) * 100\n",
    "\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(\"\\nEnsemble Model:\")\n",
    "print(f\"RMSE: {ensemble_rmse:.3f}\")\n",
    "print(f\"MAE: {ensemble_mae:.3f}\")\n",
    "print(f\"MAPE: {ensemble_mape:.2f}%\")\n",
    "\n",
    "for model in ['LSTM', 'NHITS']:\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"RMSE: {eval_results[model]['RMSE']:.3f}\")\n",
    "    print(f\"MAE: {eval_results[model]['MAE']:.3f}\")\n",
    "    print(f\"MAPE: {eval_results[model]['MAPE']:.2f}%\")\n",
    "\n",
    "# Print future predictions\n",
    "print(\"\\nFuture Predictions (next 5 periods):\")\n",
    "future_predictions = Y_hat_future[['ds', 'LSTM', 'NHITS', 'ENSEMBLE']].head()\n",
    "future_predictions[['LSTM', 'NHITS', 'ENSEMBLE']] = future_predictions[['LSTM', 'NHITS', 'ENSEMBLE']].round(3)\n",
    "print(future_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
